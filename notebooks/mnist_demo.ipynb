{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fde0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sadl.backend:Cupy backend unavailable; falling back to numpy (cpu)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "import sadl\n",
    "from sadl import xp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016199ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN_SAMPLES = 60_000\n",
    "N_TEST_SAMPLES = 10_000\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "N_TRAIN_BATCHES = math.ceil(N_TRAIN_SAMPLES / BATCH_SIZE) # mnist train has 60k images\n",
    "N_TEST_BATCHES = math.ceil(N_TEST_SAMPLES / BATCH_SIZE) # mnist test has 10k images\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9712a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"ylecun/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc4ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(examples):\n",
    "    # we could also use sadl.tensor here, but xp (numpy/cupy) is sufficient because we just transform the data once\n",
    "    pixel_values = [xp.array(img, dtype=xp.float32).flatten() for img in examples[\"image\"]]\n",
    "    examples[\"pixel_values\"] = [(pv / 255.0 - 0.1307) / 0.3081 for pv in pixel_values]\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2167540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a38644269e420c8ed69aa1065865a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train = ds[\"train\"].map(normalize, remove_columns=[\"image\"], batched=True)\n",
    "ds_eval = ds[\"test\"].map(normalize, remove_columns=[\"image\"], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d625ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sadl_tensors(batch, onehot=True):\n",
    "    x = sadl.tensor(batch[\"pixel_values\"], dtype=xp.float32)\n",
    "    y = sadl.tensor(xp.eye(10)[batch[\"label\"]] if onehot else batch[\"label\"])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e93d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sadl.Mlp([\n",
    "    sadl.Linear(dim_in=784, dim_out=784),\n",
    "    sadl.Linear(dim_in=784, dim_out=10),\n",
    "])\n",
    "log_softmax = sadl.LogSoftmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = sadl.Adam(params=list(model.parameters), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d733d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.copy_to_device(device=DEVICE)\n",
    "log_softmax = log_softmax.copy_to_device(device=DEVICE)\n",
    "optimizer = optimizer.copy_to_device(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ed72e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sadl.no_grad_fn\n",
    "def eval(model, ds_eval) -> float:\n",
    "    n_correct = 0\n",
    "    n_seen = 0\n",
    "\n",
    "    for batch in tqdm(\n",
    "        ds_eval.iter(batch_size=BATCH_SIZE),\n",
    "        desc=f\"Evaluating\",\n",
    "        total=N_TEST_BATCHES,\n",
    "    ):\n",
    "        x, y, = to_sadl_tensors(batch, onehot=False)\n",
    "\n",
    "        x = x.copy_to_device(device=DEVICE)\n",
    "        y = y.copy_to_device(device=DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        n_correct += xp.sum(logits.argmax(axis=-1) == y).item()\n",
    "        n_seen += y.shape[0]\n",
    "\n",
    "\n",
    "    return n_correct / n_seen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd87d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 235/235 [00:11<00:00, 20.88it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.93it/s]\n",
      "INFO:__main__:Train loss: 1.586968335241684\n",
      "INFO:__main__:Eval accuracy: 60.35%\n",
      "Epoch 2: 100%|██████████| 235/235 [00:11<00:00, 20.90it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.88it/s]\n",
      "INFO:__main__:Train loss: 1.2990329332054729\n",
      "INFO:__main__:Eval accuracy: 74.41%\n",
      "Epoch 3: 100%|██████████| 235/235 [00:11<00:00, 20.73it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.01it/s]\n",
      "INFO:__main__:Train loss: 1.054761533942816\n",
      "INFO:__main__:Eval accuracy: 78.80%\n",
      "Epoch 4: 100%|██████████| 235/235 [00:11<00:00, 20.80it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.54it/s]\n",
      "INFO:__main__:Train loss: 0.7989026072572353\n",
      "INFO:__main__:Eval accuracy: 81.74%\n",
      "Epoch 5: 100%|██████████| 235/235 [00:11<00:00, 20.66it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.58it/s]\n",
      "INFO:__main__:Train loss: 0.8073050154381131\n",
      "INFO:__main__:Eval accuracy: 83.16%\n",
      "Epoch 6: 100%|██████████| 235/235 [00:11<00:00, 20.61it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.73it/s]\n",
      "INFO:__main__:Train loss: 0.6920435279561444\n",
      "INFO:__main__:Eval accuracy: 84.13%\n",
      "Epoch 7: 100%|██████████| 235/235 [00:11<00:00, 20.67it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.78it/s]\n",
      "INFO:__main__:Train loss: 0.6960311752552543\n",
      "INFO:__main__:Eval accuracy: 85.24%\n",
      "Epoch 8: 100%|██████████| 235/235 [00:11<00:00, 20.73it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.79it/s]\n",
      "INFO:__main__:Train loss: 0.6650085647688414\n",
      "INFO:__main__:Eval accuracy: 86.06%\n",
      "Epoch 9: 100%|██████████| 235/235 [00:11<00:00, 20.48it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.61it/s]\n",
      "INFO:__main__:Train loss: 0.4984394953850038\n",
      "INFO:__main__:Eval accuracy: 86.33%\n",
      "Epoch 10: 100%|██████████| 235/235 [00:11<00:00, 20.65it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.12it/s]\n",
      "INFO:__main__:Train loss: 0.6548320826564156\n",
      "INFO:__main__:Eval accuracy: 86.80%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    ds_train_iter = ds_train.shuffle(seed=epoch).iter(batch_size=BATCH_SIZE)\n",
    "    \n",
    "    for batch in tqdm(\n",
    "        ds_train_iter,\n",
    "        desc=f\"Epoch {epoch+1}\",\n",
    "        total=N_TRAIN_BATCHES,\n",
    "    ):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y, = to_sadl_tensors(batch)\n",
    "\n",
    "        x = x.copy_to_device(device=DEVICE)\n",
    "        y = y.copy_to_device(device=DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        loss = -xp.mean(xp.sum(log_softmax(logits) * y, axis=-1))\n",
    "\n",
    "        optimizer.backward(loss=loss)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    eval_accuracy = eval(model, ds_eval)\n",
    "\n",
    "    logger.info(f\"Train loss: {loss.item()}\")\n",
    "    logger.info(f\"Eval accuracy: {eval_accuracy*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
