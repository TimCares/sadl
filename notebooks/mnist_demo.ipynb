{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fde0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sadl.backend:Cupy backend unavailable; falling back to numpy (cpu)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "import sadl\n",
    "from sadl import xp\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016199ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN_SAMPLES = 60_000\n",
    "N_TEST_SAMPLES = 10_000\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "N_TRAIN_BATCHES = math.ceil(N_TRAIN_SAMPLES / BATCH_SIZE) # mnist train has 60k images\n",
    "N_TEST_BATCHES = math.ceil(N_TEST_SAMPLES / BATCH_SIZE) # mnist test has 10k images\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "DEVICE = sadl.TensorDevice(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9712a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"ylecun/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc4ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(examples):\n",
    "    # we could also use sadl.tensor here, but xp (numpy/cupy) is sufficient because we just transform the data once\n",
    "    # we do not use \"xp\" here, as we want the data to be processed once on the CPU, which numpy ensures\n",
    "    #   also, since HF datasets are memory-mapped via Arrow, we cannot use the GPU here\n",
    "    pixel_values = [np.asarray(img, dtype=np.float32).flatten() for img in examples[\"image\"]]\n",
    "    examples[\"pixel_values\"] = [(pv / 255.0 - 0.1307) / 0.3081 for pv in pixel_values]\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2167540",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds[\"train\"].map(normalize, remove_columns=[\"image\"], batched=True)\n",
    "ds_eval = ds[\"test\"].map(normalize, remove_columns=[\"image\"], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d625ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sadl_tensors(batch, onehot=True):\n",
    "    x = sadl.tensor(batch[\"pixel_values\"], dtype=xp.float32)\n",
    "    y = sadl.tensor(xp.eye(10)[batch[\"label\"]] if onehot else batch[\"label\"])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e93d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sadl.Mlp([\n",
    "    sadl.Linear(dim_in=784, dim_out=784),\n",
    "    sadl.Linear(dim_in=784, dim_out=10),\n",
    "])\n",
    "log_softmax = sadl.LogSoftmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1834b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = sadl.Adam(params=list(model.parameters), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45d733d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.copy_to_device(device=DEVICE)\n",
    "log_softmax = log_softmax.copy_to_device(device=DEVICE)\n",
    "optimizer = optimizer.copy_to_device(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ed72e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sadl.no_grad_fn\n",
    "def eval(model, ds_eval) -> float:\n",
    "    n_correct = 0\n",
    "    n_seen = 0\n",
    "\n",
    "    for batch in tqdm(\n",
    "        ds_eval.iter(batch_size=BATCH_SIZE),\n",
    "        desc=f\"Evaluating\",\n",
    "        total=N_TEST_BATCHES,\n",
    "    ):\n",
    "        x, y, = to_sadl_tensors(batch, onehot=False)\n",
    "\n",
    "        x = x.copy_to_device(device=DEVICE)\n",
    "        y = y.copy_to_device(device=DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        n_correct += xp.sum(logits.argmax(axis=-1) == y).item()\n",
    "        n_seen += y.shape[0]\n",
    "\n",
    "\n",
    "    return n_correct / n_seen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd87d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 235/235 [00:11<00:00, 19.72it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 23.06it/s]\n",
      "INFO:__main__:Train loss: 0.14618203607341762\n",
      "INFO:__main__:Eval accuracy: 91.35%\n",
      "Epoch 2: 100%|██████████| 235/235 [00:11<00:00, 19.68it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.99it/s]\n",
      "INFO:__main__:Train loss: 0.20826065363333\n",
      "INFO:__main__:Eval accuracy: 91.06%\n",
      "Epoch 3: 100%|██████████| 235/235 [00:11<00:00, 19.68it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.71it/s]\n",
      "INFO:__main__:Train loss: 0.2988995469283524\n",
      "INFO:__main__:Eval accuracy: 91.12%\n",
      "Epoch 4: 100%|██████████| 235/235 [00:11<00:00, 19.59it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.84it/s]\n",
      "INFO:__main__:Train loss: 0.28610512831558643\n",
      "INFO:__main__:Eval accuracy: 92.18%\n",
      "Epoch 5: 100%|██████████| 235/235 [00:11<00:00, 19.63it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.89it/s]\n",
      "INFO:__main__:Train loss: 0.20096048015391968\n",
      "INFO:__main__:Eval accuracy: 92.01%\n",
      "Epoch 6: 100%|██████████| 235/235 [00:11<00:00, 19.63it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.62it/s]\n",
      "INFO:__main__:Train loss: 0.41751983153346045\n",
      "INFO:__main__:Eval accuracy: 91.88%\n",
      "Epoch 7: 100%|██████████| 235/235 [00:12<00:00, 19.50it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.48it/s]\n",
      "INFO:__main__:Train loss: 0.26185136385323465\n",
      "INFO:__main__:Eval accuracy: 91.95%\n",
      "Epoch 8: 100%|██████████| 235/235 [00:12<00:00, 19.56it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.70it/s]\n",
      "INFO:__main__:Train loss: 0.2960733969864793\n",
      "INFO:__main__:Eval accuracy: 91.95%\n",
      "Epoch 9: 100%|██████████| 235/235 [00:12<00:00, 19.51it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.47it/s]\n",
      "INFO:__main__:Train loss: 0.2593649862265205\n",
      "INFO:__main__:Eval accuracy: 92.04%\n",
      "Epoch 10: 100%|██████████| 235/235 [00:12<00:00, 19.48it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:01<00:00, 22.67it/s]\n",
      "INFO:__main__:Train loss: 0.4848655937750892\n",
      "INFO:__main__:Eval accuracy: 91.90%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    ds_train_iter = ds_train.shuffle(seed=epoch).iter(batch_size=BATCH_SIZE)\n",
    "    \n",
    "    for batch in tqdm(\n",
    "        ds_train_iter,\n",
    "        desc=f\"Epoch {epoch+1}\",\n",
    "        total=N_TRAIN_BATCHES,\n",
    "    ):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y, = to_sadl_tensors(batch)\n",
    "\n",
    "        x = x.copy_to_device(device=DEVICE)\n",
    "        y = y.copy_to_device(device=DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        loss = -xp.mean(xp.sum(log_softmax(logits) * y, axis=-1))\n",
    "\n",
    "        optimizer.backward(loss=loss)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    eval_accuracy = eval(model, ds_eval)\n",
    "\n",
    "    logger.info(f\"Train loss: {loss.item()}\")\n",
    "    logger.info(f\"Eval accuracy: {eval_accuracy*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
